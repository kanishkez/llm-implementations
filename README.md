In this repo I try to implement the architectures behind modern llms 


So far done with: 
1. Transformer 
2. KV Caching
3. Flash Attention ( just a rough algorithm no cuda code )

Also check out my blog where I sometimes explain these concepts: https://kanishkez.github.io/#blogs
